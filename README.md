# Group Project: Forecasting Crimes in Dallas using actual DPD Data
This repository contains the R code and data files for a group project on crime data analysis. The main goal of the project was to explore the patterns and trends of crime incidents reported by the Dallas Police Department from 2014 to 2021, and to build forecast models to identify the factors that influence the type and severity of crimes.
## Project Mission/Goals
This project aims to forecast crime trends in Dallas County by using Sparse Vector Auto Regressive (SVAR) modeling with a HLAG penalty, which can capture the relationships between different crime types over time. The project compares the crime patterns in TAAG (Targeted Action Area Grids) and non-TAAG areas, which have different levels of criminal activity and policing measures. The project also evaluates the performance of SVAR modeling against other methods, such as traditional VAR and AR models, using the weighted mean forecast error as the metric. The project demonstrates that SVAR modeling can produce the most accurate predictions for both TAAG and non-TAAG areas, and that it can help the Dallas Police Department allocate its resources more effectively and efficiently.
## My Role and Contributions
As a member of the group, I was responsible for the entire data workflow in R, which included the following steps:
- Data cleaning: I performed various data quality checks, such as removing duplicates, handling missing values, correcting data types, and standardizing variable names and formats.
- Data transformations: I applied various data transformations, such as filtering, grouping, aggregating, joining, and reshaping, to create new data sets that were suitable for data modeling and data evaluation.
- Data modeling: I used different time series models with were Sparse Var with HLag penalty, Sparse Var, VAR, and AR models, to build forecast models for the type and number of crimes a week in advance, based on the features such as location, time, day, month, and year of the incidents.
- Data evaluation: I developed a custom model evaluation method that compared the performance of different models on different data sets, for out of sample one step ahead predictions and calculated the RMSE. I also created tables to visualize the results.
The R code for each of these steps is well-documented and organized in one script, which can be found in the Code folder. The Data folder contains the raw data file (Police_Incidents1.csv) and all other intermediate and final data files that were used in the project. The names and descriptions of these files are also provided in the R code as comments.
The markdown file (codeall.md) provides a clear and comprehensive overview of the code, tables, and figures that were generated in the project. It also shows the main findings and insights from the data analysis and the model evaluation.
## Writing and Presentation
I wrote the part of the report that explained the data workflow that I was responsible for in R, using a clear and concise language that was appropriate for the intended audience, which consisted of other students, instructors, and researchers in the field of data science/statistics. I also included relevant code snippets, tables, and figures to illustrate the steps and results of the data workflow.
I presented my part of the report to the audience using a PowerPoint presentation, which can be found in the Final Report and Presentation folder. I used bullet points, graphs, and charts to summarize the main points and findings from the data workflow. I also answered the questions and feedback from the audience in a polite and professional manner.

